<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Welcome to Shiliang Zhang's Homepage</title>
<style type="text/css">
#home table tr td strong {
  font-size: 14px;
}
.name {
  font-size: 18px;
}
.name_fig {
  text-align: center;
  font-size: 18px;
  font-weight: bold;
  font-family: Calibri, Times, serif;
}
.table2 {
  text-align: left;
  font-family: Calibri, Times, serif;
}
.table_title {
  font-size: 18px;
  line-height: normal;
  font-family: Calibri, Times, serif;
}

researchinterests {
  font-size: 18px;
}
interests {
  font-size: 18px;
  text-align: left;
}
.interests {
  font-size: 20px;
  font-family: Calibri, Times, serif;
  text-align: left;
}
.text {
  font-family: Calibri, Times, serif;
}


</style>
</head>


<body>
  
  <table align="center" bgcolor="white" border="0" style="height: 100%" width="500">
  <tbody>
    <tr>
      <td valign="top">
      <table  width="1000" border="0" align="center">
        <tbody>
          <tr>
            <td align="center" valign="middle" width="120"><img src="Shiliang.jpg" width="120"  style="margin-top: 15pt" />&nbsp;<br />
            &nbsp;</td>
              <td valign="middle" width="562"><strong><font style="font-size: 16pt" face="Calibri">Shiliang Zhang</font></strong><br/>
<font face="Calibri" style="font-size: 14pt">Assistant Professor<br/>
Department of Comptuer Science, School of EE&CS, Peking University<br/>
Address: Room 513/515, Yanyuan Building, Peking University, Beijing, China<br/> 
Email: slzhang.jdl AT pku.edu.cn<br/> 
<a href="https://scholar.google.com/citations?user=7phvKK4AAAAJ&hl=zh-CN" target="_blank">Google Scholar Profile</a>
  </td><td width="80"></font>
            <td align="left" valign="middle" width="80"><img src="pkulogo.jpg" style="margin-top: 15pt" width="80" />&nbsp;<br />
            &nbsp;</td>
          </tr>
        </tbody>
      </table>
  
  <table width="720" border="0" align="center">
    <tr>
      <td><img name="" src="separator3.jpg" width="900" height="6" /></td>
    </tr>
  </table>

  <table width="1000" border="0" align="center">
    <tr>
      <td><font face="Calibri" style="font-size: 12.5pt"><p align="justify"><strong>Brief Bio: </strong>Shiliang Zhang is leading the Media and Vision Computing Group at Institute of Digital Media, Peking University. He received the Ph.D. degree from Institute of Computing Technology, Chinese Academy of Sciences in 2012 with honors. After that, he was a Postdoctoral Fellow in University of Texas at San Antonio and a Postdoctoral Scientist in NEC Labs America, Cupertino, CA. </p>
        <p style="margin-top:-6pt" align="justify">He has authored or co-authored over 70 papers in journals and conferences, including IEEE Trans. on Pattern Analysis and Machine Intelligence (T-PAMI), IEEE Trans. on Image Processing (T-IP), IEEE Trans. on Multimedia (T-MM), ACM Multimedia, CVPR, ICCV, ECCV, IJCAI, and AAAI. His research
interests include large-scale image retrieval and computer vision. He was a recipient of the Distinguished Young Scholar Fund of Beijing Natural Science Foundation, Outstanding Doctoral Dissertation Awards from the Chinese Academy of Sciences and Chinese Computer Federation, the President Scholarship from the Chinese Academy of Sciences, the NEC Laboratories America Spot Recognition Award, and the Microsoft Research Fellowship, etc. He was a recipient of the Top 10% Paper Award at the IEEE MMSP 2011. </p>
        <p style="margin-top:-6pt" align="justify">He serves as Associate Editor of IET Computer Vision, Guest Editor of ACM TOMM, TPC Co-chairs in CVPR and ICPR workshops, active reviewer for 20+ Journals including ACM Computing Survey, IJCV, T-PAMI, T-IP, and TPC member for 10+ top-tier conferences including ICCV, CVPR, ECCV, AAAI, IJCAI, NIPS, and ACM MM. His research is funded by the National Key Research and Development Program of China, National Natural Science Foundation of China, Beijing Natural Science Foundation, Microsoft Research, etc. </p>        
        
        <p style="margin-top:-6pt" align="justify"><strong>Internship and Graduate Students (both Ph.D. and  Master) Opening for 2021:</strong> We are looking for self-motivated candidates who have solid mathematical backgrounds, strong English ability, and strong coding skills. If you are interested in doing research on Computer Vision and Multimedia, and want to apply your algorithms to real problems like Internet image search, autonomous driving, please send detailed CV to me.<br />
      </p></font></td>
    </tr>
    
    
  </table>    
  
  <div><br/>
    <table width="1000" border="0" align="center">
      <tr>
        <th class="interests" scope="col" align="center"><font face="Calibri" style="font-size: 16pt">Research Highlight</font></th>  
      </tr>
   <div>
      <table align="center" width="300">
        <tbody>
          <tr>
            <td valign="top">
            <table border="0" cellspacing="7" width="200">
              <tbody>
                <tr>
                  <td align="center" valign="bottom" >
                  <p><img border="0" height="130" src="pvreid.jpg"></p>
                  <p style="text-align: center" ><font face="Calibri" style="font-size: 12.5pt">Person and vehicle ReID</font></p>
                  </td>

                  <td align="center" valign="bottom" ><img border="0" height="130" src="fgvc.jpg">
                  <p style="text-align: center"><font face="Calibri" style="font-size: 12.5pt">Fine-grained visual categorization</font></p>
                  </td>
                  <td align="center" valign="bottom" ><img border="0" height="130" src="lsis.jpg" >
                  <p style="text-align: center"><font face="Calibri" style="font-size: 12.5pt">Large-scale image search</font></p>
                  </td>
                  <td align="center" valign="bottom" ><img height="130" src="su.jpg">
                  <p style="text-align: center"><font face="Calibri" style="font-size: 12.5pt">Scene Understanding</font></p>
                  </td>
                </tr>
              </tbody>
            </table>
          </td>
        </tr>
      </table>
    </div>
    </table>
    </div>
  </div>
  <div></div>
  
  
  <div><br/>
  <table width="1000" border="0" align="center">
      <tr>
        <th class="interests" scope="col"><font face="Calibri" style="font-size: 16pt">News</font></th>
      </tr>
      <div>
      <table width="1000" border="0" align="center">
        <tr>
          <td width="980" valign="top" style="margin-left:-10pt"><ul align="justify" ><font face="Calibri" style="font-size: 12.5pt" style=“line-height: 16pt">
            <li class="text" style="">[2020. 07], one person reid paper is accepted by <strong>ECCV 2020</strong>. It uses temporal consistency to boost reid accuracy. </li>
            <li class="text" style="">[2020. 07], one paper on edge and contour detection is accepted by <strong>IEEE T-PAMI</strong>. It achieves SOTA performance with lightweight CNN. </li>
            <li class="text" style="">[2020. 06], as the leading guest editor, Dr. Zhang is co-ogranizing an <strong>ACM TOMM special issue on Fine-Grained Visual Recognition and re-IDentification</strong>! Please check the <a href="https://dl.acm.org/pb-assets/static_journal_pages/tomm/pdf/CFP_FGVRreID-1592406610240.pdf">CFP</a> and contribute!</li>
            <li class="text" style="">[2020. 06], we are ogranizing an <strong>ICPR2020 workshop: Fine-Grained Visual Recognition and re-IDentification (FGVRID)</strong>! <a href="https://fgvrid.github.io">website</a></li>
            <li class="text" style="">[2020. 04], The code of our CVPR 2020 papers is available. <a href="https://github.com/kennethwdk/MLCReID" target="_blank">link1</a> <a href="https://github.com/zhongyingji/APNet" target="_blank">link2</a> </li></li>
            <li class="text" style="">[2020. 03], one paper on vehicle reid is accepted by <strong>IEEE T-CSVT</strong>. </li>
            <li class="text" style="">[2020. 02], one paper on person search is accepted by <strong>CVPR 2020</strong>. Congratulations to Yingji for his first paper! </li>
            <li class="text" style="">[2020. 02], one paper on unsupervised person reid is accepted by <strong>CVPR 2020 as oral paper</strong>. Congratulations to Dongkai for his first paper!</li>
            <li class="text" style="">[2020. 01], one paper on video person reid is accepted by <strong>IEEE T-IP</strong>. The code will be released. </li>
            <li class="text" style="">[2019. 11], the dataset and code of our ICCV19 work GLTR for person reid are available. <a href="https://www.pkuvmc.com/dataset.html" target="_blank">link</a> </li>
            <li class="text" style="">[2019. 10], one paper on vehicle reid is accepted by <strong>IEEE T-IP</strong>.  </li>
            <li class="text" style="">[2019. 07], one paper on video representation learning is accepted by <strong>ICCV'19</strong>. </li>
            <li class="text" style="">[2019. 07], Longhui and Jianzhong have got their master degree! <strong>Congratulations to them and wish they have a great future!</strong></li>
            <li class="text" style="">[2019. 06], one paper on person reid is accepted by <strong>IEEE T-PAMI</strong>. Congratulations to Jianing for his first journal paper! </li>
            <li class="text" style="">[2019. 05], one paper on person reid is accepted by <strong>IJCAI'19</strong>. Congratulations to Shunan for his first paper! </li>
            <li class="text" style="">[2019. 04], we will show our <strong>EAGER (Edge-Aided imaGe undERstanding) system</strong> at ACM ICMR'19!</li>
            <li class="text" style="">[2019. 03], one paper on edge detection is accepted by <strong>CVPR'19</strong>. </li>
            <li class="text" style="">[2019. 02], the code and model of our <strong>CDbin descriptor</strong> has been released. Please download and try: <a href="https://github.com/JM-IP/CDbin" target="_parent">link</a>.</li>
            <li class="text" style="">[2019. 01], our paper on binary descriptor CDbin is accepted by <strong>IEEE T-CSVT</strong>, Congratulations to Jianming for his first paper! </li>
            <li class="text" style="">[2018. 12], one paper on person reid is accepted by <strong>IEEE T-IP</strong>.</li>
            <li class="text" style="">[2018. 11], the code of our AAAI'19 paper has been released: <a href="https://github.com/pkuvmc/M3D" target="_blank">link</a>.</li>
            <li class="text" style="">[2018. 11], one paper on video person reid is accepted by <strong>AAAI'19</strong>. </li>
            <li class="text" style="">[2018. 08], a more complete version of GLAD is accepted by <strong>IEEE T-MM</strong>.</li>
            <li class="text" style="">[2018. 06], as one of the 12 research groups worldwild, our team received the <strong>Nvidia Pioneering Research Award at CVPR'18</strong>, Congratulations to all!</li>
            <li class="text" style="">[2018. 05], one paper on multi-object tracking is accepted by <strong>IEEE T-IP</strong>.</li>
            <li class="text" style="">[2018. 05], the slides of our FG 2018 tutorial <strong>Person Re-Identification: Recent Advances and Challenges</strong> can be downloaded: <a href="https://github.com/pkuvmc/pkuvmc.github.io/tree/master/FG2018-Tutorial/" target="_parent">link</a>.</li>
            <li class="text" style="">[2018. 04], the code of <strong>Person Transfer GAN (PTGAN)</strong> has been released: <a href="https://github.com/JoinWei-PKU/PTGAN" target="_parent">link</a>.</li>
            <li class="text" style="">[2018. 04], one demo paper is accepted by ACM ICMR'18. We will show a <strong>person and vehicle Re-ID system</strong> at ACM ICMR 2018!</li>
            <li class="text" style="">[2018. 04], one paper on vehicle reid is accepted by </strong>IEEE ICME'18</li>
            <li class="text" style="">[2018. 03], one paper on person reid is accepted as <strong>Spotlight paper in CVPR '18</strong>. </li>
            <li class="text" style="">[2018. 02], we are organizing a tutorial on FG'18: <strong>Person Re-Identification: Recent Advances and Challenges. </strong>.</li>
            <li class="text" style="">[2018. 02], one paper on video emotion recognition is accepted by <strong>IEEE T-MM</strong>.</li>
            <li class="text" style="">[2018. 01], the code of our ACM MM17 work GLAD is released: <a href="https://github.com/JoinWei-PKU/GLAD" target="_parent">link</a>.</li>
            <li class="text" style="">[2018. 01], the dataset of our ACM MM17 work One-Shot Fine-Grained Instance Retrieval is released: <a href="https://pan.baidu.com/s/1zrDbu9ydKDZBqQ_2_plYww" target="_parent">link</a>.</li>
            <li class="text" style="">[2018. 01], one paper on fine-grained visual categorization is accepted by<strong> IEEE T-IP</strong>.</li>
            <li class="text" style="">[2018. 01], one paper on attribute based person reid is accepted by <strong>IEEE T-PAMI</strong>.</li>
            
          </ul></td>
        </tr>
      </table>
      </div>
 </table>
 </div>
    
  <div><br/>
  <table width="1000" border="0" align="center">
      <tr>
        <th class="interests" scope="col"><font face="Calibri" style="font-size: 16pt">Recent Publications in Top-Tier Journals and Conferences<a href="../publications/publications_revised.html" style="text-decoration: none">
    (complete list...)</a></font></th>
      </tr>
      <div>
      <table width="1000" border="0" align="center">
        <tr>
          <td width="980" valign="top" style="margin-left:-10pt"><ul align="justify" ><font face="Calibri" style="font-size: 12.5pt"  style=“line-height: 16pt">
          <li><span ><strong>[T-PAMI 2020]</strong>: Bi-Directional Cascade Network for Perceptual Edge Detection.</span></li>
          <span class="text"> Jianzhong He, <strong>Shiliang Zhang*</strong>, Ming Yang, Yanhu Shan, and Tiejun Huang.</span> <span class="text"> 
          <li><span ><strong>[T-IP 2020]</strong>: Multi-scale Temporal Cues Learning for Video Person Re-Identification.</span></li>
          <span class="text"> Jianing Li, <strong>Shiliang Zhang*</strong>, and Tiejun Huang.</span> <span class="text">   
          <li><span ><strong>[T-CSVT 2020]</strong>: Multi-View Spatial Attention Embedding for Vehicle Re-Identification.</span></li>
          <span class="text"> Shangzhi Teng, <strong>Shiliang Zhang*</strong>, Qingming Huang, and Nicu Sebe. </span> <span class="text">   
            
          <li><span ><strong>[CVPR 2020 Oral]</strong>: Unsupervised Person Re-identification via Multi-label Classification.</span></li>
          <span class="text"> Dongkai Wang and <strong>Shiliang Zhang*</strong>.</span> <span class="text">    
          <li><span ><strong>[CVPR 2020]</strong>: Robust Partial Matching for Person Search in the Wild.</span></li>
          <span class="text"> Yingji Zhong, Xiaoyu Wang, and <strong>Shiliang Zhang*</strong>.</span> <span class="text">    
          <li><span ><strong>[ECCV 2020]</strong>: Joint Visual and Temporal Consistency for Unsupervised Domain Adaptive Person Re-Identification.</span></li>      
          <span class="text"> Jianing Li and <strong>Shiliang Zhang*</strong>.</span> <span class="text">      
         
            
          <li><span ><strong>[T-PAMI 2019]</strong>: Pose-Guided Representation Learning for Person Re-Identification.</span></li>
          <span class="text"> Jianing Li, <strong>Shiliang Zhang*</strong>, Qi Tian, Meng Wang, and Wen Gao.</span> <span class="text">    
          <li><span ><strong>[T-IP 2019]</strong>: Group-Group Loss Based Global-Regional Feature Learning for Vehicle Re-Identification.</span></li>       
          <span class="text"> Xiaobin Liu, <strong>Shiliang Zhang*</strong>, Xiaoyu Wang, Richang Hong, and Qi Tian.</span> <span class="text">             
          <li><span ><strong>[T-IP 2019]</strong>: Deep Representation Learning with Part Loss for Person Re-Identification.</span></li>           
          <span class="text"> Hantao Yao, <strong>Shiliang Zhang</strong>, Yongdong Zhang, Changsheng Xu, and Qi Tian.</span> <span class="text">             
          <li><span ><strong>[T-CSVT 2019]</strong>: CDbin: Compact Discriminative Binary Descriptor Learned with Efficient Neural Network.</span></li>          
          <span class="text"> Jianming Ye, <strong>Shiliang Zhang*</strong>, Tiejun Huang, and Yong Rui. </span> <span class="text">              
            
          <li><span ><strong>[ICCV 2019]</strong>: Global-Local Temporal Representations for Video Person Re-Identification.</span></li>        
          <span class="text"> Jianing Li, Jingdong Wang, Qi Tian, Wen Gao, and <strong>Shiliang Zhang*</strong>. </span> <span class="text">      
          <li><span ><strong>[IJCAI 2019]</strong>: Resolution Invariant Person Re-Identification.</span></li>             
          <span class="text"> Shunan Mao, <strong>Shiliang Zhang*</strong>, and Ming Yang. </span> <span class="text">       
          <li><span ><strong>[CVPR 2019]</strong>: Bi-Directional Cascade Network for Perceptual Edge Detection.</span></li>       
          <span class="text"> Jianzhong He, <strong>Shiliang Zhang*</strong>, Ming Yang, Yanhu Shan and Tiejun Huang.</span> <span class="text">       
          <li><span ><strong>[AAAI 2019 Oral]</strong>: Multi-scale 3D Convolution Network for Video Based Person Re-Identification.</span></li>
          <span class="text"> Jianing Li, <strong>Shiliang Zhang*</strong>, and Tiejun Huang.</span> <span class="text">      
            
          <li><span ><strong>[T-PAMI 2018]</strong>: Multi-Task learning with low rank attribute embedding for multi-camera person re-identification.</span></li>
          <span class="text"> Chi Su, Fan Yang, <strong>Shiliang Zhang*</strong>, Qi Tian, Larry S. Davis, and Wen Gao. </span> <span class="text">      
          <li><span ><strong>[T-IP 2018]</strong>: AutoBD: Automated Bi-level Description for scalable fine-grained visual categorization.</span></li>
          <span class="text"> Hantao Yao, <strong>Shiliang Zhang</strong>, Yongdong Zhang, Jintao Li, and Qi Tian.</span> <span class="text">      
          <li><span ><strong>[T-IP 2018]</strong>: Interacting Tracklets for Multi-object Tracking.</span></li>   
          <span class="text"> Long Lan, Xinchao Wang, <strong>Shilinag Zhang</strong>, Dacheng Tao, Wen Gao, and Thomas Huang. </span> <span class="text">      
          <li><span ><strong>[T-MM 2018]</strong>: GLAD: Global-Local-Alignment Descriptor for Scalable Person Re-Identification.</span></li>        
          <span class="text"> Longhui Wei, <strong>Shiliang Zhang*</strong>, Hantao Yao, Wen Gao, and Qi Tian.</span> <span class="text">      
          <li><span ><strong>[T-MM 2018]</strong>: Speech Emotion Recognition Using Deep Convolutional Neural Network and Discriminant Temporal Pyramid Matching.</span></li>
          <span class="text"> Shiqing Zhang, <strong>Shiliang Zhang</strong>, Tiejun Huang, and Wen Gao.  </span> <span class="text">      
          <li><span ><strong>[Pattern Recognition 2018]</strong>: Multi-type Attributes Driven Multi-camera Person Re-Identification.</span></li>
          <span class="text"> Chi Su, <strong>Shiliang Zhang*</strong>, Junliang Xing, Qi Tian, and Wen Gao. </span> <span class="text">      
          <li><span ><strong>[T-CSVT 2018]</strong>: Learning Affective Features with a Hybrid Deep Model for Audio-Visual Emotion Recognition.</span></li>
          <span class="text"> Shiqing Zhang, <strong>Shiliang Zhang</strong>, Tiejun Huang, Wen Gao, and Qi Tian. </span> <span class="text">      
            
          <li><span ><strong>[CVPR 2018 Spotlight]</strong>: Person Transfer GAN to Bridge Domain Gap for Person Re-Identification.</span></li>    
          <span class="text"> Longhui Wei, <strong>Shilinag Zhang*</strong>, Wen Gao, and Qi Tian.  </span> <span class="text">  
            
          <li><span ><strong>[Pattern Recognition 2017]</strong>: Attributes Driven Tracklet-to-tracklet Person Re-Identification Using Latent Prototypes Space Mapping.</span></li>
          <span class="text"> Chi Su, <strong>Shiliang Zhang*</strong>, Fan Yang, Qi Tian, Wen Gao, and Larry S Davis. </span> <span class="text">  
          <li><span ><strong>[ICCV 2017]</strong>: Pose-driven Deep Convolutional Model for Person Re-Identification.</span></li>
          <span class="text"> Chi Su, Jianing Li, <strong>Shiliang Zhang*</strong>, Junliang Xing, Wen Gao, and Qi Tian. </span> <span class="text">  
          <li><span ><strong>[ACM MM 2017]</strong>: GLAD: Global-Local-Alignment Descriptor for Pedestrian Retrieval.</span></li>                    
          <span class="text"> Longhui Wei, <strong>Shiliang Zhang*</strong>, Hantao Yao, Wen Gao, and Qi Tian.  </span> <span class="text">  
          <li><span ><strong>[ACM MM 2017]</strong>: One-Shot Fine-Grained Instance Retrieval.</span></li>       
          <span class="text"> Hantao Yao, <strong>Shiliang Zhang*</strong>, Yongdong Zhang, Qi Tian.</span> <span class="text">  
            
          </font></ul></td>
        </tr>
      </table>
    </div>
      
    </table>
     </div>

<div><br/>
  <table width="1000" border="0" align="center">
      <tr>
        <th class="interests" scope="col">Sponsors</th>
      </tr>

      <tr>
        <td align="left" valign="bottom" width="633"><img src="sponsor.jpg" style="border-left-width: 0px; border-right-width: 0px; border-bottom-width: 0px; border-top-width: 0px" width="550" />&nbsp;<br />
        &nbsp;</td>
      </tr>
   
      <div>

   
    <table width="1000" border="0" align="center">
    <tr>
      <td><img name="" src="separator.jpg" width="800" height="2" /></td>
    </tr>
  </table>

  
  
  <table width="1000" border="0" align="center">
    <tr>
      <td align="center"><font face="Calibri" style="font-size:11pt">Updated 07/2020</font></td>
    </tr>
  </table>
</div>
</body>
</html>

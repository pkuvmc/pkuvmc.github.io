<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Transitional//EN" "http://www.w3.org/TR/xhtml1/DTD/xhtml1-transitional.dtd">
<html xmlns="http://www.w3.org/1999/xhtml">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<title>Welcome to Shiliang Zhang's Homepage</title>
<style type="text/css">

.publications {
	text-align: center;
	font-weight: bold;
  font-size: 16pt;
	font-family: Calibri, Times, serif;
}
.papers {
	font-size: 12pt;
}

.years {
	margin-align: left;
	font-size: 12pt;
  font-family: Calibri;
}

body,td,th {
	color: rgb(0,0,0);
	font-family: Calibri, Times, serif;
}
a:link {
	color: rgb(0,0,0);
}
a:active {
	color: rgb(0,0,255);
}
</style>
</head>

<body link="#000000" vlink="#0000FF" alink="#0000FF">

<table width="720" border="0" align="center">
  <tr>
    <td class="publications">Publications</td>
  </tr>
</table>
<table width="720" border="0" align="center">
  <tr>
    <td><img src="../home/separator.jpg" width="850" height="2" /></td>
  </tr>
</table>

<font face="Calibri" style="font-size: 12pt">

<table width="850" border="0" align="center">
  <tr>
    <td class="years"><b>2018</b>
  </tr>
	
  <tr>
    <td height="130" align="left"><img src="jianming_CDbin.png" width="250" ></td>
    <td height="130" align="left"><p align="justify">Jianming Ye, Shiliang Zhang, Tiejun Huang, Yong Rui. CDbin: Compact Discriminative Binary Descriptor Learned with Efficient Neural Network. <em>TCSVT</em>, 2019.<a href="https://github.com/JM-IP/CDbin">[code]</a> <li><span ><a href="../publications/CDbin_project_page.html" target="_parent">project page</a></p>
  </tr>
	
  <tr>
    <td height="130" align="left"><img src="jianing_3d_18.png" width="250" ></td>
    <td height="130" align="left"><p align="justify">Jianing Li, Shiliang Zhang, Tiejun Huang. Multi-scale 3D Convolution Network for Video Based Person Re-Identification. <em>AAAI</em>, 2019.<a href="https://arxiv.org/abs/1811.07468" target="_parent">[pdf]</a><a href="https://github.com/pkuvmc/M3D">[code]</a></p>
  </tr>
	
   <tr>
    <td height="130" align="left"><img src="2018_pic0.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify"><font face="Calibri" style="font-size: 12pt">L. Wei, S. Zhang, W. Gao, and Q. Tian. Person Transfer GAN to Bridge Domain Gap for Person Re-Identification, <em>IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</em>, 2018.<a href="https://arxiv.org/pdf/1711.08565" target="_parent">[pdf]</a><a href="msmt17.html" target="_parent">[datasetpage]</a></font></p>
</p>
      
  </tr>

  <tr>
    <td height="130" align="left"><img src="icme18-xb.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">X. Liu, S. Zhang, Q. Huang, and W. Gao. RAM: A Region-Aware Deep Model for Vehicle Re-Identification. <em>IEEE International Conference on Multimedia and Expo. (ICME)</em>, 2018.<a href="https://arxiv.org/abs/1806.09283" target="_parent">[pdf]</a><a href="https://github.com/pkuvmc/RAM">[code]</a></p>
  </tr>
	
  <tr>
    <td height="130" align="left"><img src="2018_pic1.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">H. Yao, S. Zhang, Y. Zhang, J. Li, and Q. Tian. AutoBD: Automated Bi-level Description for scalable fine-grained visual categorization. <em>IEEE Trans. on Image Processing(TIP)</em>, 27(1): 10-23, 2018.<a href="http://ieeexplore.ieee.org/document/8036263/" target="_parent">[pdf]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2018_pic2.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">C. Su, S. Zhang, J. Xing, Q. Tian, and W. Gao. Multi-type attributes driven multi-camera person re-identification, <em>Elsevier Pattern Recognition,</em> 75: 77-89, 2018.<a href="https://www.sciencedirect.com/science/article/pii/S0031320317302686" target="_parent">[pdf]</a></p>
      
  </tr>
</table>


<table width="850" border="0" align="center">
  <tr>
    <td height="20" class="years" style="margin-top: 20pt"><b style="margin-top: 20pt">2017</b>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic1.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">C. Su, F. Yang, S. Zhang, Q. Tian, L. S. Davis, and W. Gao. Multi-Task learning with low rank attribute embedding for multi-camera person re-identification. <em>IEEE Trans. on Pattern Analysis and Machine Intelligence(TPAMI)</em>, DOI: 10.1109/TPAMI.2017.2679002<a href="http://www.umiacs.umd.edu/~fyang/papers/iccv15.pdf" target="_parent">[pdf]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic2.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">S. Zhang, S. Zhang, T. Huang, W. Gao, and Q. Tian. Learning affective features with a hybrid deep model for audio-visual emotion recognition. <em>IEEE Trans. on Circuits and Systems for Video Technology(TCSVT)</em>, DOI: 10.1109/TCSVT.2017.2719043<a href="http://ieeexplore.ieee.org/iel7/76/4358651/07956190.pdf" target="_parent">[pdf]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic3.jpg" width="250"></td>
    <td height="130" align="left"><p align="justify">S. Zhang, S. Zhang, T. Huang, and W. Gao. Speech emotion recognition using deep convolutional neural network and discriminant temporal pyramid matching. <em>IEEE Trans. on Multimedia(TMM)</em>, DOI: 10.1109/TMM.2017.2766843<a href="http://ieeexplore.ieee.org/iel7/6046/4456689/08085174.pdf" target="_parent">[pdf]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic4.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">C. Su, S. Zhang, Y. Fan, G. Zhang, Q. Tian, W. Gao, and L. S Davis. Attributes driven tracklet -to-tracklet person re-identification using latent prototypes space mapping. <em>Elsevier Pattern Recognition</em>, 66: 4-15, 2017.<a href="https://www.sciencedirect.com/science/article/pii/S0031320317300067" target="_parent">[pdf]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic5.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">X. Liu, S. Zhang, T. Huang, and Q. Tian. E2BoWs: an end-to-end bag-of-words model via deep convolutional neural network for image retrieval. Accepted by <em>Elsevier Neurocomputing</em>, 2017.<a href="https://arxiv.org/pdf/1709.05903" target="_parent">[pdf]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic6.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">H. Yao, D. Zhang, J. Li, J. Zhou, S. Zhang, Y. Zhang. DSP: Discriminative Spatial Part modeling for fine-grained visual categorization. <em>Elsevier Image Vision Comput.</em>, 63: 24-37, 2017.<a href="https://www.sciencedirect.com/science/article/pii/S0262885617300847" target="_parent">[pdf]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic7.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">C. Su, J. Li, S. Zhang, J. Xing, W. Gao, and Q. Tian. Pose-driven Deep Convolutional Model for Person Re-identification. <em>International Conference on Computer Vision (ICCV)</em>, 2017.<a href="https://arxiv.org/pdf/1709.08325" target="_parent">[pdf]</a><a href="https://github.com/kaneiri/PDC-ICCV2017" target="_parent">[code]</a></a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic8.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">L. Wei, S. Zhang, H. Yao, W. Gao, and Q. Tian. GLAD: Global-Local-Alignment Descriptor for Pedestrian Retrieval. <em>ACM International Conference on Multimedia (ACM MM)</em>, 2017.<a href="https://arxiv.org/pdf/1709.04329" target="_parent">[pdf]</a></p><a href="https://github.com/JoinWei-PKU/GLAD" target="_parent">[code]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic9.jpg" width="250" ></td>
    <td height="130" align="left"><p align="justify">H. Yao, S. Zhang, Y. Zhang, Q. Tian. One-Shot Fine-Grained Instance Retrieval. <em>ACM International Conference on Multimedia (ACM MM)</em>, 2017.<a href="https://arxiv.org/pdf/1707.00811" target="_parent">[pdf]</a><a href="https://pan.baidu.com/s/1zrDbu9ydKDZBqQ_2_plYww">[dataset]</a></p>
  </tr>
  <tr>
    <td height="130" align="left"><img src="2017_pic10.jpg" width="250"></td>
    <td height="130" align="left"><p align="justify"> H. Yao, S. Zhang, D. Zhang, Y. Zhang, J. Li, Y. Wang, Q. Tian. Large-Scale Person Re-Identification as Retrieval. <em>IEEE International Conference on Multimedia and Expo (ICME)</em>, 2017.<a href="http://ieeexplore.ieee.org/document/8019485/" target="_parent">[pdf]</a></p>
  </tr>

</table>


<table width="850" border="0" align="center">
  <tr>
  	<td class="years"><b style="margin-top: 60pt ">2016</b>
  </tr>
  <tr>
    <td valign="top" class="papers"  ><ol align="justify">
      <li style="margin-top: -10pt">
        H. Yao, S. Zhang, Y. Zhang, J. Li, and Q. Tian. Coarse-to-fine description for fine-grained visual categorization. <em>IEEE Trans. on Image Processing(TIP)</em>, 25(10): 4858-4872, 2016. <a href="https://ieeexplore.ieee.org/iel7/83/7529254/07536636.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        C. Su, S. Zhang, J. Xing, W. Gao, and Qi Tian. Deep attributes driven multi-camera person re-identification. <em>European Conference on Computer Vision (ECCV)</em>, 2016.<a href="https://arxiv.org/pdf/1605.03259.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, S. Zhang, T. Huang, and W. Gao. Multimodal Deep convolutional neural network for audio-visual emotion recognition. <em>ACM International Conference on Multimedia Retrieval (ICMR)</em>, 2016.<a href="http://delivery.acm.org/10.1145/2920000/2912051/p281-zhang.pdf?ip=162.105.95.174&id=2912051&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519715726_788285a969ae5ded8760b3dc22574646" target="_parent">[pdf]</a>
      </li>

    </ol></td>
    </tr>

    
  <tr>
  	<td class="years"><b style="margin-top: 20pt">2015</b>
    </tr>
  
  <tr>
    <td valign="top" class="papers"><ol align="justify">
      <li style="margin-top: -10pt">
        S. Zhang, Q. Huang, Q. Tian,  and W. Gao. Large-scale Image Search - From the Perspective of Local  Descriptor, <em>SpringerBriefs</em>, Springer,  Under Editing, 2015.
      </li>
      <li>
        S.  Zhang, X. Wang, Y. Lin, and Q. Tian. Cross indexing with grouplets. <em>IEEE Transactions on Multimedia</em> (<em>T-MM</em>), 2015.<a href="https://ieeexplore.ieee.org/iel7/6046/4456689/07273920.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S.  Zhang, M.  Yang, X. Wang, Y. Lin, and Q. Tian. Semantic-aware co-indexing for image  search. <em>IEEE Transactions on Pattern  Analysis and Machine Intelligence</em> (<em>T-PAMI</em>),  2015.<strong></strong><a href="https://ieeexplore.ieee.org/iel7/34/4359286/07072494.pdf
" target="_parent">[pdf]</a>
      </li>
      <li>
        S.  Zhang,  Q. Tian, Q. Huang, Y. Rui, and W. Gao. Multi-order visual phrase for scalable  partial-duplicate visual search. <em>Multimedia  System Journal </em>(<em>MMSJ</em>), 2015.<a href="https://link.springer.com/content/pdf/10.1007%2Fs00530-014-0369-x.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        J. Cai, Z. Zha, M. Wang, S. Zhang, and Q. Tian. An Attribute-assisted Reranking Model for Web Image Search. <em>IEEE Transactions on Image Processing </em>(<em>T-IP</em>), 2015.<a href="https://ieeexplore.ieee.org/iel7/83/4358840/06960834.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S.  Zhang.  Efficient indexing for large-scale image search.&nbsp;<em>ACM International Conference on International  Conference on Internet Multimedia Computing and Service </em>(<em>ICIMCS</em>) 2015.<a href="http://delivery.acm.org/10.1145/2810000/2808578/a86-zhang.pdf?ip=162.105.95.174&id=2808578&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519716016_48422a1dc9dfa5cff3453383d9b9f74e" target="_parent">[pdf]</a>
      </li>
      <li>
        C. Su, F. Yang, S. Zhang, Q. Tian, L. Davis, W. Gao. Multi-Task Learning with Low  Rank Attribute Embedding for Person Re-identification, <em>IEEE  International Conference on Computer Vision</em>(<em>ICCV</em>), 2015.<a href="www.umiacs.umd.edu/~fyang/papers/iccv15.pdf
" target="_parent">[pdf]</a>
      </li>
      <li>
        H. Yao,&nbsp;S. Zhang,&nbsp;F. Xie,&nbsp;Y.  Zhang,&nbsp;D. Zhang,&nbsp;Y. Su,&nbsp;Q. Tian. Orientational Spatial Part  Modeling for Fine-Grained Visual Categorization.&nbsp;<em>IEEE</em> <em>International Conference  on</em> <em>Mobile Service</em> 2015.<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=7226712" target="_parent">[pdf]</a>
      </li>
      <li>
        Y. Zhou, D. Zeng, S. Zhang, and Q. Tian. Augmented feature fusion for image retrieval system. <em>ACM International Conference on Multimedia Retrieval (ICMR)</em>, 2015.<a href="https://dl.acm.org/ft_gateway.cfm?id=2749288&type=pdf" target="_parent">[pdf]</a>
      </li>


  
    </ol></td>
  </tr>
  <tr>
  	<td class="years"><b style="margin-top: 20pt">2014</b>
  </tr>
  
  <tr>
    <td valign="top" class="papers"><ol align="justify">
     <li style="margin-top: -10pt">
        S.  Zhang,  Q. Tian, Q. Huang, Y. Rui, and W. Gao. USB: ultra short binary descriptor for  fast image matching and retrieval. Accepted, <em>IEEE Transactions on Image Processing </em>(<em>T-IP</em>), 2014.<strong></strong><a href="https://ieeexplore.ieee.org/iel7/83/4358840/06832500.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S.  Zhang,  Q. Tian, Q. Huang, Y. Rui, and W. Gao. Cascade category-aware visual search.<em> IEEE Transactions on Image Processi</em>ng (<em>T-IP</em>), Volume 23, Issue 6, pp.  2514-2527,2014.<strong></strong><a href="https://ieeexplore.ieee.org/iel7/83/4358840/06800030.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S.  Zhang,  Q. Tian, Q. Huang, and Y. Rui. Embedding multi-order spatial clues for scalable  visual matching and retrieval. <em>IEEE  Journal on Emerging and Selected Topics in Circuits and Systems </em>(<em>JETCAS</em>), 2014.<a href="https://ieeexplore.ieee.org/iel7/5503868/5751207/06720206.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S.  Zhang,  Q. Tian, G. Hua, Q. Huang, S. Jiang, and W. Gao. ObjectPatchNet: Towards scalable and semantic image annotation and retrieval. <em>Computer Vision and Image Understanding </em>(<em>CVIU</em>)<em>,</em> Volume 118, pp. 16-29, January, 2014.<a href="http://www.jdl.ac.cn/doc/2011/201511522485674562_2014_cviu_objectpatchnet%20towards%20scalable%20and%20semantic%20image%20annotation%20and%20retrieval.pdf">[pdf]</a>
      </li>
      <li>
        Q. Luo, S. Zhang, T. Huang, W. Gao, and Q. Tian. Indexing heterogeneous features with superimages. <em>International  Journal of Multimedia Information Retrieval </em>(<em>IJMIR</em>), 2014.<a href="https://link.springer.com/content/pdf/10.1007%2Fs13735-014-0064-x.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        Q. Luo#, S. Zhang#((#: equal contribution), T. Huang, W. Gao, and Q.  Tian. Superimage: packing semantic-relevant images for indexing and retrieval. <strong><em>Oral  paper</em></strong> (acceptance rate: 19%, 21/110), <em>ACM International Conference on Multimedia Retrieval </em>(<em>ICMR</em>), 2014.<a href="http://delivery.acm.org/10.1145/2580000/2578741/p41-Luo.pdf?ip=162.105.95.174&id=2578741&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519718831_88d1c0960579d663b021e974641150f5" target="_parent">[pdf]</a>
      </li>
      <li>
        Q. Luo, S. Zhang, T. Huang, W. Gao, and Q. Tian. Hybrid-indexing multi-type  features for large-scale image search. <em>Asian  Conference on Computer Vision</em> (<em>ACCV</em>),  2014. <a href="https://link.springer.com/chapter/10.1007/978-3-319-16865-4_29" target="_parent">[pdf]</a>
      </li>
      <li>
        Z. Niu, S. Zhang, X. Gao, and Q. Tian. Personalized visual vocabulary  adaption for social image applications. Short paper (acceptance rate: 30%) <em>ACM International Conference on Multimedia </em>(<em>ACM MM</em>), 2014. <a href="http://delivery.acm.org/10.1145/2660000/2655006/p993-niu.pdf?ip=162.105.95.174&id=2655006&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519718906_ad9f112be78309536c210c5f8aad2148" target="_parent">[pdf]</a>
      </li>

    </ol></td>
  </tr>
  <tr>
  	<td class="years"><b style="margin-top: 20pt">2013</b>
  </tr>
  
  <tr>
    <td valign="top" class="papers"><ol align="justify">
      <li style="margin-top: -10pt">
        S. Zhang, Q. Tian, Q.  Huang, and W, Gao. Edge-SIFT: Discriminative binary descriptor for scalable partial-duplicate  mobile search. <em>IEEE Transactions on Image  Processing </em>(<em>T-IP</em>), Volume 22,  Issue 7, pp. 2889-2902, July, 2013.<strong></strong><a href="https://ieeexplore.ieee.org/iel7/83/4358840/06476016.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, M. Yang, X. Wang, Y. Lin, and Q. Tian. Semantic-aware co-indexing for  image search. <em>IEEE International  Conference on Computer Vision </em>(<em>ICCV</em>),  2013.<a href="https://ieeexplore.ieee.org/iel7/34/4359286/07072494.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Tian, Q. Huang, W. Gao, and Y. Rui. Multi-order visual phrase for  scalable image search. <strong><em>Oral paper</em></strong>, <em>ACM International Conference on International Conference on Internet  Multimedia Computing and Service </em>(<em>ICIMCS</em>),  2013.<a href="https://dl.acm.org/ft_gateway.cfm?id=2499833&ftid=1390942&dwn=1&CFID=11066182&CFTOKEN=c0468b75bdaa6187-5C4CFDC7-C2A0-B3AC-8826FC7EAE146E69" target="_parent">[pdf]</a>
      </li>
      <li>
        Q. Luo#, S. Zhang#((#: equal contribution), Q. Tian, T. Huang, and W.  Gao. Scalable mobile search with binary phrases. <strong><em>Oral paper</em></strong>, <em>ACM International Conference on  International Conference on Internet Multimedia Computing and Service </em>(<em>ICIMCS</em>), 2013.<a href="http://delivery.acm.org/10.1145/2500000/2499815/p66-luo.pdf?ip=162.105.95.174&id=2499815&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519717108_12cda1e2c0a313c08e92eb63323873a1" target="_parent">[pdf]</a>
      </li>
      <li>
        J. Cai, Z. Zha, H. Luan, S. Zhang, and Q. Tian. Learning Attribute-aware Dictionary for Image Classification and Search. <strong><em>Oral paper</em></strong>, <em>ACM International Conference on Multimedia Retrieval (ICMR)</em>, 2013.<a href="http://delivery.acm.org/10.1145/2470000/2461473/p33-cai.pdf?ip=162.105.95.174&id=2461473&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519717163_5a5b79d8d9532aee2fedc1bf3124539e" target="_parent">[pdf]</a>
      </li>


    </ol></td>
  </tr>
  <tr>
  	<td class="years" style="margin-top: 40pt"><b>Before 2012</b>
  </tr>
  
  <tr>
    <td valign="top" class="papers"><ol align="justify">
      <li style="margin-top: -10pt">
        S. Zhang, Q. Tian, G. Hua,  Q. Huang, and W. Gao. Generating descriptive visual words and visual phrases  for large-scale image applications. <em>IEEE  Transactions on Image Processing </em>(<em>T-IP</em>),  Volume 20, Issue 9, pp. 2664-2677, September, 2011.<a href="https://ieeexplore.ieee.org/iel5/83/4358840/05732695.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        Y. Cui, S. Luo, Q. Tian, S. Zhang, Y. Peng, L. Jiang, and J. Jin. Mutual information-based emotion recognition, <em>Pacific-Rim Conference on Multimedia (PCM)</em>, 2011.<a href="https://link.springer.com/content/pdf/10.1007%2F978-1-4614-3501-3_39.pdf" target="_parent">[pdf]</a>
      </li>

      <li>
        Y. Cui, J. Jin, S. Zhang, S. Luo, and Q. Tian. Music video affective understanding using feature importance analysis. <em>ACM International Conference on Image and Video Retrieval (ACM CIVR)</em>, pp. 213-219, 2010.<a href="http://delivery.acm.org/10.1145/1820000/1816074/p213-cui.pdf?ip=162.105.95.174&id=1816074&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519717409_48a3c028744fd7740c7b4bed5d9eec7c" target="_parent">[pdf]</a>
      </li>
      <li>
        Y. Cui, J. Jin, S. Zhang, S. Luo, Q. Tian. Correlation-based feature selection and regression. <em>Pacific-Rim Conference on Multimedia (PCM)</em>, pp. 25-35, 2010.<a href="https://link.springer.com/content/pdf/10.1007/978-3-642-15702-8_3.pdf" target="_parent">[pdf]</a>
      </li>


      <li>
        S. Zhang, Q. Huang, S. Jiang,  W. Gao, and Q. Tian. Affective visualization and retrieval for music video. <em>IEEE Transactions on Multimedia </em>(<em>T-MM</em>)<em>,</em>Volume  12, Issue 6, pp.  510-522, October, 2010.<a href="http://ieeexplore.ieee.org/xpl/tocresult.jsp?isnumber=5571813">[pdf]</a>
      </li>

      <li>
       S. Zhang, Q. Tian, G. Hua,  W. Zhou, Q. Huang, and W. Gao. Modeling spatial and semantic cues for large-scale near-duplicated image retrieval. <em>Computer Vision and Image Understanding </em>(<em>CVIU</em>), Volume 115, Issue 3, pp. 403-414, March, 2010.<a href="http://www.jdl.ac.cn/doc/2011/201163017584923775_modeling%20spatial%20and%20semantic%20cues%20for%20large-scale%20near-duplicated%20image%20retrieval.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        Q. Tian, S. Zhang, W. Zhou, R. Ji, B. Ni, and N.  Sebe. Building descriptive and discriminative visual codebook for large-scale  image applications. <em>International Journal  of Multimedia Tools and Applications </em>(<em>IJMTA</em>),Volume  51, Issue 2, pp. 441-477, November, 2010.<a href="https://link.springer.com/content/pdf/10.1007%2Fs11042-010-0636-6.pdf" target="_parent">[pdf]</a>
      </li>
	    <li>
        S. Zhang, Q. Tian, Q. Huang, and W. Gao. Objectbook  construction for large-scale semantic-aware image retrieval, <strong><em>Oral  paper and top 10% paper award, </em></strong><em>IEEE  International Workshop on Multimedia Signal Processing </em>(<em>IEEE MMSP</em>), 2011.<a href="https://ieeexplore.ieee.org/iel5/6082085/6093769/06093776.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Huang, G. Hua, S. Jiang, W. Gao, and Q. Tian,  Building contextual visual vocabulary for large-scale image applications, <strong><em>Full  paper and best paper candidate in content track</em></strong>, <em>ACM International Conference on Multimedia </em>(<em>ACM MM</em>), pp. 501-510, October, 2010.<a href="http://delivery.acm.org/10.1145/1880000/1874018/p501-zhang.pdf?ip=162.105.95.174&id=1874018&acc=ACTIVE%20SERVICE&key=BF85BBA5741FDC6E%2EAC95BC9DA5A3FA7E%2E4D4702B0C3E38B35%2E4D4702B0C3E38B35&__acm__=1519717749_d633ab9fbc5698f50363742e23f2e586" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Huang, Y. Lu, W. Gao, and Q. Tian. Building  pair-wise visual word tree for efficient image re-ranking. <strong><em>Oral paper</em></strong><em>, IEEE International Conference on  Acoustics, Speech, and Signal Processing </em>(<em>ICASSP</em>), pp. 794-797, March, 2010.<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5494964" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Tian, G. Hua, Q. Huang, and S. Li. Descriptive  visual words and visual phrases for image applications. <strong><em>Full paper</em></strong><em>, ACM International Conference on Multimedia </em>(<em>ACM MM</em>), pp. 75-84, October, 2009.<a href="https://dl.acm.org/ft_gateway.cfm?id=1631285&ftid=673024&dwn=1&CFID=10960635&CFTOKEN=732e837660595b4c-5E25C329-9E91-674E-A6F12B5CCD93D091" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Tian, Q. Huang, W. Gao, and S. Li. Utilizing  affective analysis for efficient movie browsing. <em>IEEE International Conference on Image Processing </em>(<em>ICIP</em>), pp. 1853-1856, November, 2009.<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=5413590" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Huang, Q. Tian, S. Jiang, and W. Gao.  Personalized MTV affective analysis using user profile. <strong><em>Oral paper</em></strong>, <em>Pacific-Rim Conference on Multimedia </em>(<em>PCM</em>), pp. 327-337, 2008.<a href="https://link.springer.com/content/pdf/10.1007%2F978-3-540-89796-5.pdf" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Huang, Q. Tian, S. Jiang, and W. Gao. i.MTV-an  integrated system for MTV affective analysis. <strong><em>Technical demonstration</em></strong><em>, ACM International Conference on Multimedia </em>(<em>ACM MM</em>), pp. 985-986, October,  2008.<a href="https://www.researchgate.net/publication/221573657_iMTV_an_integrated_system_for_mtv_affective_analysis" target="_parent">[pdf]</a>
      </li>
      <li>
        S. Zhang, Q. Tian, S. Jiang, Q. Huang, and W. Gao. Affective  MTV analysis based on arousal and valence features. <em>IEEE International Conference on Multimedia and Expo </em>(<em>ICME</em>), pp. 1369-1372, June, 2008.<a href="http://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=4607698" target="_parent">[pdf]</a>
      </li>

  
    </ol></td>
  </tr>
  
</table>
<table width="850" border="0" align="center">
  <tr>
    <td><img src="../home/separator.png" width="850" height="2" /></td>
  </tr>
</table>



</body>
</html>
